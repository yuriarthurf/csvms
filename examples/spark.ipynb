{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo: Spark\n",
    "\n",
    "`spark-defaults.conf`\n",
    "\n",
    "```bash\n",
    "spark.jars.packages org.apache.spark:spark-avro_2.12:3.3.0\n",
    "spark.sql.warehouse.dir data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nm_fruta: string (nullable = true)\n",
      " |-- tp_fruta: string (nullable = true)\n",
      " |-- vl_fruta: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(\n",
    "    schema = [\n",
    "        \"nm_fruta\",\n",
    "        \"tp_fruta\"],\n",
    "    data=[\n",
    "        ('banana','doce'),\n",
    "        ('limão','azedo'),\n",
    "        ('maçã','doce')\n",
    "    ]\n",
    ")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+\n",
      "|nm_fruta|tp_fruta|vl_fruta|\n",
      "+--------+--------+--------+\n",
      "|   limão|   azedo|     1.2|\n",
      "|  banana|    doce|     0.0|\n",
      "|    maçã|    doce|     1.3|\n",
      "+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.write.mode(\"overwrite\").saveAsTable(\"lista_frutas\")\n",
    "spark.sql(\"select * from lista_frutas\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.coalesce(1).write.format(\"parquet\").option(\"compression\",\"uncompressed\").mode(\"overwrite\").save(\"data/colunar\")\n",
    "df.coalesce(1).write.format(\"avro\").option(\"compression\",\"uncompressed\").mode(\"overwrite\").save(\"data/linear\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('csvms-l4jZKfPM-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a84bf26869892adb843eae20f10e89c204f3e1c57aed8fbbbb6e912b0386733"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
